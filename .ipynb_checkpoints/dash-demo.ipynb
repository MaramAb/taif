{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install flask_caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "from copy import deepcopy\n",
    "import csv\n",
    "import sys\n",
    "import pathlib\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "from flask_caching import Cache\n",
    "import sys\n",
    "import dash_reusable_components as drc\n",
    "import utils\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        images = DiffAugment(images, policy='color,translation') #DiffAugment is used here\n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
    "        \n",
    "class Net(ImageClassificationBase):\n",
    "    def __init__(self, num_classes=2, num_channels=3):\n",
    "        super().__init__()\n",
    "        preloaded = torchvision.models.densenet161(pretrained=True)\n",
    "        self.features = preloaded.features\n",
    "        self.features.conv0 = nn.Conv2d(num_channels, 96, 7, 2, 3)\n",
    "        self.classifier = nn.Linear(2208, num_classes, bias=True)\n",
    "        self.bn = nn.BatchNorm1d(2208)\n",
    "        del preloaded\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = F.adaptive_max_pool2d(out, (1, 1)).view(features.size(0), -1)\n",
    "        #out = self.bn(out)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "def predict_image(img, model):\n",
    "    # Convert to a batch of 1\n",
    "    img = ToTensor()(img)\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    classes = ['autistic', 'non autistic']\n",
    "    return classes[preds[0].item()]\n",
    "\n",
    "Net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net.load_state_dict(torch.load('./autism_best_model.pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "app = JupyterDash(__name__)\n",
    "server = app.server\n",
    "\n",
    "def serve_layout():\n",
    "    \n",
    "    # App Layout\n",
    "    return html.Div(\n",
    "        id=\"root\",\n",
    "        children=[\n",
    "            # Main body\n",
    "            html.Div(\n",
    "                id=\"app-container\",\n",
    "                children=[\n",
    "                    # Banner display\n",
    "                    html.Div(\n",
    "                        id=\"banner\",\n",
    "                        children=[\n",
    "                            html.Img(\n",
    "                                id=\"logo\", src=app.get_asset_url(\"taif-logo.png\")\n",
    "                            ),\n",
    "                            html.H2(\"Taif: ASD Diagnosis System\", id=\"title\"),\n",
    "                        ],\n",
    "                    ),\n",
    "                    html.Div(\n",
    "                        id=\"image\",\n",
    "                        children=[\n",
    "                            # The Interactive Image Div contains the dcc Graph\n",
    "                            # showing the image, as well as the hidden div storing\n",
    "                            # the true image\n",
    "                            html.Div(\n",
    "                                id=\"div-interactive-image\",\n",
    "                                children=[\n",
    "                                    utils.GRAPH_PLACEHOLDER\n",
    "                                ],\n",
    "                            )\n",
    "                        ],\n",
    "                    ),\n",
    "                ],\n",
    "            ),\n",
    "            # Sidebar\n",
    "            html.Div(\n",
    "                id=\"sidebar\",\n",
    "                children=[\n",
    "                    #TO-DO:\n",
    "                    #add prediction component could be h1 or h2...\n",
    "                    html.Div([\n",
    "                        html.H1(\"Prediction:\"),\n",
    "                        html.H3(id=\"prediction\")\n",
    "                    ]),\n",
    "                    drc.Card(\n",
    "                        [\n",
    "                            dcc.Upload(\n",
    "                                id=\"upload-image\",\n",
    "                                children=[\n",
    "                                    \"Drag and Drop or \",\n",
    "                                    html.A(children=\"Select an Image\"),\n",
    "                                ],\n",
    "                                # No CSS alternative here\n",
    "                                style={\n",
    "                                    \"color\": \"darkgray\",\n",
    "                                    \"width\": \"100%\",\n",
    "                                    \"height\": \"50px\",\n",
    "                                    \"lineHeight\": \"50px\",\n",
    "                                    \"borderWidth\": \"1px\",\n",
    "                                    \"borderStyle\": \"dashed\",\n",
    "                                    \"borderRadius\": \"5px\",\n",
    "                                    \"borderColor\": \"darkgray\",\n",
    "                                    \"textAlign\": \"center\",\n",
    "                                    \"padding\": \"2rem 0\",\n",
    "                                    \"margin-bottom\": \"2rem\",\n",
    "                                },\n",
    "                                accept=\"image/*\",\n",
    "                            ),\n",
    "                    \n",
    "                        ]\n",
    "                    ),\n",
    "                ],\n",
    "            ),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "app.layout = serve_layout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output(\"div-interactive-image\", \"children\"),\n",
    "       [\n",
    "        Input(\"upload-image\", \"contents\")\n",
    "       ],\n",
    "    [\n",
    "        State(\"upload-image\", \"filename\"),\n",
    "    ],\n",
    ")\n",
    "def update_graph_interactive_image(\n",
    "    content,\n",
    "    new_filename\n",
    "):\n",
    "\n",
    "\n",
    "    \n",
    "    # Parse the string and convert to pil\n",
    "    string = content.split(\";base64,\")[-1]\n",
    "    im_pil = drc.b64_to_pil(string)\n",
    "\n",
    "    # Update the image signature, which is the first 200 b64 characters\n",
    "    return [\n",
    "        drc.InteractiveImagePIL(\n",
    "            image_id=\"interactive-image\",\n",
    "            image=im_pil,\n",
    "        )\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a function to update the prediction component you created above here \n",
    "#output would be the prediction component\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"prediction\", \"children\"),\n",
    "       [\n",
    "        Input(\"upload-image\", \"contents\")\n",
    "       ],\n",
    "    [\n",
    "        State(\"upload-image\", \"filename\"),\n",
    "    ],\n",
    ")\n",
    "def update_prediction(\n",
    "    content,\n",
    "    new_filename\n",
    "):\n",
    " \n",
    "    # Parse the string and convert to pil\n",
    "    string = content.split(\";base64,\")[-1]\n",
    "    im_pil = drc.b64_to_pil(string)\n",
    "    pred =  predict_image(im_pil, Net)\n",
    "    # Update the image signature, which is the first 200 b64 characters\n",
    "    return 'We think your child is {}'.format(pred)\n",
    "\n",
    "\n",
    "#and use your prediction function here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "# Running the server\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
